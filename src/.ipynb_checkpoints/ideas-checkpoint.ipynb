{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b89df471",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pypi_xmlrpc\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0f01af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://pypi.org/pypi/{}/json'\n",
    "packages = pypi_xmlrpc.list_packages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "777549f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "package_info = requests.get(url.format('requests')).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "22d4fb60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requests:\n",
      "{\n",
      "    \"comment_text\": \"\",\n",
      "    \"digests\": {\n",
      "        \"md5\": \"c90a48af18eb4170dbe4832c1104440c\",\n",
      "        \"sha256\": \"210a82e678c45d433a4ad1f105974b3102a8ab5198872dc0a3238a8750d4c65e\"\n",
      "    },\n",
      "    \"downloads\": -1,\n",
      "    \"filename\": \"requests-0.10.0.tar.gz\",\n",
      "    \"has_sig\": false,\n",
      "    \"md5_digest\": \"c90a48af18eb4170dbe4832c1104440c\",\n",
      "    \"packagetype\": \"sdist\",\n",
      "    \"python_version\": \"source\",\n",
      "    \"requires_python\": null,\n",
      "    \"size\": 62046,\n",
      "    \"upload_time\": \"2012-01-22T05:08:17\",\n",
      "    \"upload_time_iso_8601\": \"2012-01-22T05:08:17.091441Z\",\n",
      "    \"url\": \"https://files.pythonhosted.org/packages/62/35/0230421b8c4efad6624518028163329ad0c2df9e58e6b3bee013427bf8f6/requests-0.10.0.tar.gz\",\n",
      "    \"yanked\": false,\n",
      "    \"yanked_reason\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"requests:\")\n",
    "print(json.dumps(package_info['releases']['0.10.0'][0], indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fac5d60",
   "metadata": {},
   "source": [
    "***IDEA*** <br>\n",
    "For packege in all packages:\n",
    "\n",
    "    1 get json\n",
    "    2 find the **first** release version with a date and save date\n",
    "    3 open a file in the format 'year-month-network.csv' representing the \n",
    "        year and moth the package was created(grouping packages together \n",
    "        that are released the same moth). If allready open do nothing\n",
    "    4 write in file repository|[dependencies...]\n",
    "END; 5 : close all files.\n",
    "\n",
    "\n",
    "***Problem***\n",
    "When making this kind of time-dependent network where we add\n",
    "nodes the dependencies may not yet exist, i.e. the development team decided\n",
    "to add dependencies after the first version. I have no way of checking the \n",
    "dependencies of each version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378be17f",
   "metadata": {},
   "source": [
    "***Addressing the problem****\n",
    "\n",
    "The problem where the requirement of a package has not been released yet\n",
    "lets say we have a dictonary of pd.DataFrames, where each key corresponds \n",
    "to a year-date sorted based on the date of the data.\n",
    "\n",
    "FOR each entry in the dictonary do:\n",
    "    FOR each entry (package, requirement) in the dataframe do:\n",
    "    \n",
    "        1 check if the ***requirement*** is in any of the dataframes from before as package\n",
    "        2 if yes : pass\n",
    "        3 if not : delete the requirement and create a standalone package(node), additionally\n",
    "            save both package and requirement together (as a tuple) in a list, say the cache list:\n",
    "        4 check if the package is in the cache list as a ***requirement***\n",
    "        5 if yes: append the pair package requirement found in the cache list to the \n",
    "            dataframe and delete entry in the cache list\n",
    "        6 if not: pass\n",
    "        7 lastly update the dataframe by making a ***set*** out of it to avoid duplicate nodes, e.g.\n",
    "            if requirement deleted (use pd.DataFrame.drop_duplicates())\n",
    "            \n",
    "    DONE\n",
    "DONE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
