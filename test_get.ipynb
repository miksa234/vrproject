{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b89df471",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pypi_xmlrpc\n",
    "import re\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import warnings\n",
    "import csv\n",
    "from numba import jit\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0f01af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://pypi.org/pypi/{}/json'\n",
    "packages = pypi_xmlrpc.list_packages()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fac5d60",
   "metadata": {},
   "source": [
    "***IDEA*** <br>\n",
    "For packege in all packages:\n",
    "\n",
    "    1 get json\n",
    "    2 find the **first** release version with a date and save date\n",
    "    3 open a file in the format 'year-month-network.csv' representing the \n",
    "        year and moth the package was created(grouping packages together \n",
    "        that are released the same moth). If allready open do nothing\n",
    "    4 write in file repository|[dependencies...]\n",
    "END; 5 : close all files.\n",
    "\n",
    "\n",
    "***Problem***\n",
    "When making this kind of time-dependent network where we add\n",
    "nodes the dependencies may not yet exist, i.e. the development team decided\n",
    "to add dependencies after the first version. I have no way of checking the \n",
    "dependencies of each version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378be17f",
   "metadata": {},
   "source": [
    "***Addressing the problem****\n",
    "\n",
    "The problem where the requirement of a package has not been released yet\n",
    "lets say we have a dictonary of pd.DataFrames, where each key corresponds \n",
    "to a year-date sorted based on the date of the data.\n",
    "\n",
    "FOR each entry in the dictonary do:\n",
    "    FOR each entry (package, requirement) in the dataframe do:\n",
    "    \n",
    "        1 check if the ***requirement*** is in any of the dataframes from before as package\n",
    "        2 if yes : pass\n",
    "        3 if not : delete the requirement and create a standalone package(node), additionally\n",
    "            save both package and requirement together (as a tuple) in a list, say the cache list:\n",
    "        4 check if the package is in the cache list as a ***requirement***\n",
    "        5 if yes: append the pair package requirement found in the cache list to the \n",
    "            dataframe and delete entry in the cache list\n",
    "        6 if not: pass\n",
    "        7 lastly update the dataframe by making a ***set*** out of it to avoid duplicate nodes, e.g.\n",
    "            if requirement deleted (use pd.DataFrame.drop_duplicates())\n",
    "            \n",
    "    DONE\n",
    "DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6de6a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a60d06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed403edb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
